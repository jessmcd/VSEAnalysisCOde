{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import glob\n",
    "from functions import convert_wind\n",
    "\n",
    "def make_1s_file(data):\n",
    "    #variable dictionary\n",
    "   \n",
    "    # variables\n",
    "    avg_temp = np.round(data['T'].resample('1S', label='right').mean(),1)\n",
    "    avg_P =    np.round(data['P'].resample('1S', label='right').mean(),1)\n",
    "    avg_RH =   np.round(data['RH'].resample('1S', label='right').mean(),1)\n",
    "    avg_ws =   np.round(data['windsp'].resample('1S', label='right').mean(),1)\n",
    "    times = avg_P.index\n",
    "    \n",
    "    # wind direction\n",
    "    u,v = convert_wind(data['windsp'], data['winddir'])\n",
    "    u_avg = u.resample('1S', label='right').mean()\n",
    "    v_avg = v.resample('1S', label='right').mean()\n",
    "    avg_wd = np.round(np.rad2deg(np.arctan2(u_avg, v_avg))+180,1) # rotate so 0 is N\n",
    "    \n",
    "    \n",
    "    # if 10Hz data used in a minute has been flagged, the whole minute will be flagged\n",
    "    # if data looks wonky, checking this number may explain why\n",
    "    tflag = data['tflag'].resample('1S', label='right').max()\n",
    "    wflag = data['wflag'].resample('1S', label='right').max()\n",
    "    \n",
    "\n",
    "    # put data into pandas dataframe\n",
    "    d = {'T':avg_temp, 'RH':avg_RH, 'P':avg_P, 'WS':avg_ws, \n",
    "         'WD':avg_wd, 'TFLAG':tflag, 'WFLAG':wflag}\n",
    "    avgmet = pd.DataFrame(data=d,index=times).replace(-999.9,np.nan)\n",
    "    avgmet.sort_index(ascending = True, inplace = True)\n",
    "    \n",
    "    return avgmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stesonet\n",
    "datadir = r'/Users/jessmcd/Documents/MyPassport_backup/VortexSE/NewAnalyses/data/'\n",
    "savedir = r'/Users/jessmcd/Documents/MyPassport_backup/VortexSE/NewAnalyses/data_1s/'\n",
    "\n",
    "col_names = ['time', 'T', 'RH', 'P', 'windsp', 'winddir', 'batt', 'tflag','wflag', 'ID']\n",
    "allfiles = glob.glob('{}*.csv'.format(datadir))\n",
    "\n",
    "for f in allfiles:\n",
    "    data10 = pd.read_csv(f, index_col=0, header=0,names=col_names, \n",
    "                         parse_dates=['time'], date_parser=pd.to_datetime)\n",
    "    if data10.empty != True:\n",
    "        data1 = make_1s_file(data10)\n",
    "        fname = f[-18:]\n",
    "        data1.to_csv('{}{}'.format(savedir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this for single sticknets\n",
    "\n",
    "datadir = r'/Users/jessmcd/Documents/MyPassport_backup/VortexSE/NewAnalyses/data/'\n",
    "savedir = r'/Users/jessmcd/Documents/MyPassport_backup/VortexSE/NewAnalyses/data_1s/'\n",
    "\n",
    "col_names = ['time', 'T', 'RH', 'P', 'windsp', 'winddir', 'batt', 'tflag','wflag', 'ID']\n",
    "allfiles = glob.glob('{}0217A_20170301.csv'.format(datadir))\n",
    "\n",
    "for f in allfiles:\n",
    "    data10 = pd.read_csv(f, index_col=0, header=0,names=col_names, \n",
    "                         parse_dates=['time'], date_parser=pd.to_datetime)\n",
    "    if data10.empty != True:\n",
    "        data1 = make_1s_file(data10)\n",
    "        fname = f[-18:]\n",
    "        data1.to_csv('{}{}'.format(savedir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rapid probes\n",
    "\n",
    "class SNFile(object):\n",
    "    def __init__(self, filename):\n",
    "        self.year = int(filename[-19:-15])\n",
    "        self.month = int(filename[-15:-13])\n",
    "        self.day = int(filename[-13:-11])\n",
    "        self.hour = int(filename[-10:-8])\n",
    "        self.minute = int(filename[-8:-6])\n",
    "        self.datetime = dt.datetime(self.year,self.month,self.day)\n",
    "        self.filename = filename\n",
    "        self.probe = filename[-25:-21]\n",
    "        f = open(self.filename)\n",
    "        header = f.readline().split()\n",
    "        self.header = header[0]\n",
    "        f.close()\n",
    "      \n",
    "    def parse(self, time):\n",
    "        \n",
    "        try:\n",
    "            timep = \"%08.1f\"%time\n",
    "            if timep == 000000.0:\n",
    "                self.datetime += dt.timedelta(days=1) \n",
    "            hour,minute,second,msec = int(timep[0:2]),int(timep[2:4]),int(timep[4:6]),int(timep[-1])\n",
    "            return self.datetime + dt.timedelta(hours=hour,minutes=minute,seconds=second,microseconds=msec*100000)\n",
    "        except:\n",
    "            if [self.year, self.month, self.day] == [2017, 3, 1]:\n",
    "                t = dt.datetime.strptime(time,'%d_%H%M%S.%f')\n",
    "                t = t.replace(year=self.year, month=self.month)\n",
    "                return t\n",
    "            else:\n",
    "                return dt.datetime.strptime(time,'%Y%m%d_%H%M%S.%f')\n",
    "    \n",
    "\n",
    "    def read(self):\n",
    "        # for rapid probes, that don't have the extra data point at the end\n",
    "        sn = pd.read_csv(self.filename, names=['time','T','RH','P','windsp','winddir','batt','flag','flag2'],\n",
    "                         dtype={'time':np.float},parse_dates=[0],date_parser=self.parse,header=1,\n",
    "                         error_bad_lines = False)\n",
    "        \n",
    "        sn['ID'] = pd.Series(self.probe,index=sn.index)\n",
    "        sn.index = sn['time']\n",
    "        return sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/Users/jessmcd/Documents/MyPassport_backup/VSE_Data/'\n",
    "savedir = r'/Users/jessmcd/Documents/MyPassport_backup/VortexSE/NewAnalyses/data_1s/'\n",
    "\n",
    "rpfiles = []\n",
    "\n",
    "deployments = ['20160331_deployment', '20160430_deployment',\n",
    "               '20170301_deployment', '20170325_deployment', '20170327_deployment1', '20170430_deployment']\n",
    "for dep in deployments:\n",
    "    if dep[0:4] == '2016':\n",
    "        rpfiles.extend(glob.glob('{}2016/Deployments/{}/reformat/*.txt'.format(basedir, dep)))\n",
    "    else: # 2017\n",
    "        rpfiles.extend(glob.glob('{}2017/deployments/{}/reformat/*.txt'.format(basedir, dep)))\n",
    "        \n",
    "for f in rpfiles:\n",
    "    data_ob = SNFile(f)\n",
    "    data10 = data_ob.read()\n",
    "    data10.rename(columns={'flag':'tflag', 'flag2':'wflag'}, inplace=True)\n",
    "    if data10.empty != True:\n",
    "        data1 = make_1s_file(data10)\n",
    "        fname = f[-25:-11]\n",
    "        data1.to_csv('{}{}.csv'.format(savedir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dealing with 2017 March 1 217A issue ... data file was never QC'd...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
